---
title: "Homework6_zc2823"
output: github_document
date: "2025-11-16"
---

```{r setup, include = FALSE}
library(tidyverse)
library(broom)
library(rvest)
library(p8105.datasets)
library(janitor)
library(scales)
library(lubridate)
library(patchwork)
library(modelr)
library(purrr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
set.seed(1)
```

# Problem 1

### Read & Cleaning Data
```{r}
homi_df = read_csv("data/homicide-data.csv") |> 
  clean_names() |> 
  mutate(
    city_state = str_c(city, ", ", state),
    victim_age = as.numeric(victim_age),
    # solved = 1; unsolved = 0
    resolved = disposition == "Closed by arrest"
  ) |> 
  # omit the specific cities & Tulsa, AL
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO")),
    !(city == "Tulsa" & state == "AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age),
    !is.na(victim_sex),
    !is.na(resolved)
  ) |> 
  mutate(
    victim_race = fct_relevel(victim_race, "White"),   # Reference: White
    victim_sex  = fct_relevel(victim_sex, "Female")    # Reference: Female
  )
```

### Logistic regression for Baltimore
```{r}
## Baltimore subset 
baltimore_df =
  homi_df |> 
  filter(city_state == "Baltimore, MD")

## Fit logistic regression
baltimore_fit = glm(
  resolved ~ victim_age + victim_sex + victim_race,
  data   = baltimore_df,
  family = binomial()
)

## Extract adjusted OR comparing male vs female victims
baltimore_or =
  baltimore_fit |> 
  tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high)

baltimore_or |> 
  knitr::kable(digits = 3)
```

### Run glm for all cities & extract ORs
```{r}
city_or_results =
  homi_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(
      data,
      \(df) glm(resolved ~ victim_age + victim_sex + victim_race,
                data = df, family = binomial())
    ),
    tidied = map(
      models,
      \(mod) tidy(mod, conf.int = TRUE, exponentiate = TRUE)
    )
  ) |> 
  select(city_state, tidied) |> 
  unnest(tidied) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high) |> 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  )
```

### Plot ORs and CIs for all cities
```{r or-plot, fig.width=8, fig.height=18}
city_or_results |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(size = 0.7) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.5) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios for Solving Homicides (Male vs Female)",
    subtitle = "Models adjusted for victim age and race",
    x = "City",
    y = "Adjusted OR"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6), lineheight = 0.9)
```

#### Comment
The plot shows substantial variation across cities in the adjusted odds ratio (OR) for solving homicides involving male victims compared to female victims, controlling for victim age and race.

A number of cities, such as Albuquerque, NM, Stockton, CA, and Fresno, CA, have ORs well above 1, indicating that cases involving male victims were more likely to be solved. However, the confidence intervals in several of these cities are wide, suggesting considerable uncertainty—likely due to smaller sample sizes or quasi-complete separation in the logistic models.

In contrast, many large cities—including Baltimore, MD, Chicago, IL, Cincinnati, OH, and New York, NY—have ORs close to or below 1, and most of their confidence intervals cross the null value of 1. This implies no strong evidence of a male–female difference in case resolution rates in these jurisdictions after adjustment.


# Problem 2

### Load the data
```{r}
data("weather_df")
weather_df = weather_df |> 
  drop_na(tmax, tmin, prcp)
```

### Define bootstrap function
```{r}
boot_samples = 
  weather_df |> 
  modelr::bootstrap(n = 5000)
```

### Produce estimates of the two quantities
```{r}
boot_results =
  boot_samples |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    glance  = map(models, glance),
    tidyres = map(models, tidy)
  ) |> 
  mutate(
    r2 = map_dbl(glance, \(g) g$r.squared),

    beta_ratio = map_dbl(tidyres, \(t) {
      b1 = t$estimate[t$term == "tmin"]
      b2 = t$estimate[t$term == "prcp"]
      b1 / b2
    })
  ) |> 
  select(r2, beta_ratio)
```

### Hist/Density plot
#### r² distribution + β1 / β2 distribution
```{r fig.width=8, fig.height=18}
p_r2 =
  boot_results |> 
  ggplot(aes(x = r2)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of R²",
    x = "R²",
    y = "Density"
  )

p_ratio =
  boot_results |> 
  ggplot(aes(x = beta_ratio)) +
  geom_density(fill = "orange", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of β1/β2",
    x = "β1/β2",
    y = "Density"
  )

p_r2 + p_ratio 
```

The bootstrap distributions of the two statistics exhibit strikingly different behaviors. The distribution of $R^2$ is extremely narrow and highly concentrated around its observed value, indicating that the strength of the linear relationship between $t_{\max}$ and the predictors is very stable across bootstrap samples. In contrast, the distribution of the ratio $\beta_1 / \beta_2$ is much wider and substantially more variable. This occurs because precipitation (the coefficient $\beta_2$) has a much weaker and less stable association with maximum temperature, making the ratio $\beta_1 / \beta_2$ highly sensitive and unstable.

Although the vertical scales of the two density plots differ due to probability density normalization, placing the distributions side-by-side is still informative. The comparison clearly shows that $R^2$ is a highly stable estimator, whereas the ratio $\beta_1 / \beta_2$ exhibits substantial uncertainty. The combined visualization therefore effectively highlights the relative variability of the two bootstrap estimators.

### 95% CI
```{r}
r2_ci =
  boot_results |> 
  summarize(
    low  = quantile(r2, 0.025),
    high = quantile(r2, 0.975)
  )

ratio_ci =
  boot_results |> 
  summarize(
    low  = quantile(beta_ratio, 0.025),
    high = quantile(beta_ratio, 0.975)
  )
```

Using the 5000 bootstrap samples, the 95% confidence interval for \(R^2\) is  
**`r round(r2_ci$low, 3)`** to **`r round(r2_ci$high, 3)`**.

For the ratio \( \beta_1 / \beta_2 \), the 95% bootstrap interval is  
**`r round(ratio_ci$low, 3)`** to **`r round(ratio_ci$high, 3)`**.

# Problem 3

### Load and clean the data
```{r}
birthweight_df =
  read_csv("data/birthweight.csv") |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian",
                              "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian",
                              "Puerto Rican", "Other")),
    malform = factor(malform,
                     levels = c(0, 1),
                     labels = c("absent", "present"))
  )

## NA check
birthweight_df |>
  summarise(across(everything(), \(x) sum(is.na(x))))
```

### Propose a regression model for birthweight
```{r}
bw_mod =
  lm(
    bwt ~ babysex + bhead + blength + gaweeks +
      ppbmi + ppwt + wtgain + momage + mrace + smoken,
    data = birthweight_df
  )

summary(bw_mod)$r.squared
```

The proposed model includes infant characteristics (sex, head circumference, length, gestational age) and maternal factors (pre-pregnancy BMI and weight, pregnancy weight gain, age, race, and smoking). These variables are biologically plausible determinants of birthweight and provide a reasonably rich main-effects model without adding very complex interaction structures.

The proposed regression model explains approximately 71.75% (R² = 0.7175) of the variability in birthweight.

#### Residuals vs fitted plot
```{r fig.width=8, fig.height=18}
bw_aug =
  birthweight_df |>
  add_predictions(bw_mod) |>
  add_residuals(bw_mod)

bw_aug |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Proposed model: residuals vs fitted values",
    x = "Fitted birthweight (grams)",
    y = "Residuals"
  ) +
  theme_minimal()
```

The residual–fitted plot shows that residuals are centered around zero with no strong curvature, suggesting that the linearity assumption is reasonably met. There is some heteroscedasticity, as residuals spread out more at higher fitted birthweights, but this pattern is common in biological data and not severe. A few outliers appear but do not drive the overall trend.

### Compare to the two other models using crossv_mc
#### Cross-validation + RMSE
```{r}
cv_df =
  crossv_mc(birthweight_df, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble)
  ) |>
  mutate(
    mod_main = map(train, ~ lm(
      bwt ~ babysex + bhead + blength + gaweeks +
        ppbmi + ppwt + wtgain + momage + mrace + smoken,
      data = .x
    )),
    mod_A = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x
    )),
    mod_B = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x
    ))
  ) |>
  mutate(
    rmse_main = map2_dbl(mod_main, test, ~ rmse(model = .x, data = .y)),
    rmse_A    = map2_dbl(mod_A,    test, ~ rmse(model = .x, data = .y)),
    rmse_B    = map2_dbl(mod_B,    test, ~ rmse(model = .x, data = .y))
  )
```

#### Organize to long + Box Plot
```{r rmse-box, fig.width=10, fig.height=6}
rmse_long =
  cv_df |>
  select(rmse_main, rmse_A, rmse_B) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) |>
  mutate(
    model = recode(
      model,
      rmse_main = "Proposed model",
      rmse_A    = "Length + gestational age",
      rmse_B    = "Head × length × sex (full interaction)"
    )
  )

## boxplot of test-set RMSE
rmse_long |>
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "Cross-validated RMSE by model",
    x = "Model",
    y = "RMSE (test set)"
  ) +
  scale_y_continuous(limits = c(250, 380)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 20, hjust = 1, size = 8),
  plot.margin = margin(10, 10, 30, 10)     
)
```

### Summary
```{r}
rmse_summary =
  rmse_long |>
  group_by(model) |>
  summarise(
    mean_rmse   = mean(rmse),
    median_rmse = median(rmse)
  )

rmse_summary |>
  knitr::kable(digits = 1, caption = "RMSE Summary by Model")
```

Using 100 Monte Carlo cross-validation splits, the proposed model achieves the lowest prediction error among the three models. The boxplot of RMSE values shows a clear separation:

* Proposed model has the smallest RMSE, with both mean and median around 273 g, indicating the most accurate predictions on held-out data.

* Head × length × sex (full interaction) performs moderately well, with mean RMSE around 289 g. Although the model is flexible, the interaction structure may introduce unnecessary complexity that does not improve predictive accuracy.

* Length + gestational age (main effects only) yields the worst predictive performance, with mean RMSE around 332 g, suggesting that using only two predictors is insufficient for capturing variation in birthweight.




